[05_circular_contigs.rb]

# parameter

# E-value cutoff for circular formation
e_thre = "1e-10"
# % identity for circular formation
pi_thre = "100"
# minimum alignment length for circular formation
al_thre = "50"

# % identity for removal of redundancy
pi_thre_rd = "95"
# % query coverage for removal of redundancy
qc_thre_rd = "95"

# minimum length for linear contigs
len_l = "5000"
# minimum length for circular contigs
len_c = "1500"

---

# input
query_fa_ = "#{dir_in_}/contig.#{query_label}.#{l_thre}.fa"

# output
out = "#{dir_out_}/contig.updated.#{query_label}.#{len_l}.c_#{len_c}"

# shori
(1) ruby ${SCRIPT_SELF_}  -d #{dir_out_} -i #{query_fa_}  -n #{n_threads} \
                          --len_l #{len_l} --len_c #{len_c} --pi_rd #{pi_thre_rd} --qc_rd #{qc_thre_rd}

------
[run_blastn_self_contig.3.rb]

# output files
out_blast_all_ = "#{dir_out_}/#{task}.all_vs_all.#{e_thre}.pi_#{pi_self}.txt"
out_blast_self_ = "#{dir_out_}/#{task}.self.#{e_thre}.pi_#{pi_self}.txt"
out_blast_circular_ = "#{dir_out_}/#{task}.circular.#{e_thre}.pi_#{pi_self}.al_#{al_self}.txt"
out_linear = "#{dir_out_}/contig.linear"
out_circular = "#{dir_out_}/contig.circular"
out_updated = "#{dir_out_}/contig.updated"

(1-1)データベースが作られていなかったらこれを作る
    # make blastdb if it does not exist.
    in_contig = "#{File.dirname(in_contig_)}/#{File.basename(in_contig_,'.*')}"
    if ! File.exist?("#{in_contig}.nsq") and ! File.exist?("#{in_contig}.nal")
        ${MAKEBLASTDB_} -in #{in_contig_}  -out #{in_contig}  -dbtype nucl  -parse_seqids
    end

(1-2)自分自身とblastn実行
    ${BLASTN_} -task #{task} -num_threads #{n_threads} -query #{in_contig_} \
               -db #{in_contig} -evalue #{e_thre} -perc_identity #{pi_self} -outfmt 6 -num_alignments 5 -out #{out_blast_all_}

(1-3)同じ配列がヒットしていたらそこだけを取る。
    awk -F "\t" '{OFS="\t"}  { if ($1 == $2) print $0 }' #{out_blast_all_} > #{out_blast_self_}

(1-4)配列一つ一つでFASTAファイルを分割
    awk '
        # ヘッダー行を検出
        /^>/ {
            # ヘッダー行から ">" とスペースを削除してファイル名を生成
            # gsub()でスペースをアンダースコアに置換し、より安全なファイル名にする
            filename = $0
            gsub(/^> *| */, "", filename)
            gsub(/ +/, "_", filename)

            # 新しいファイル名で出力ファイルを閉じて、開き直す
            # ここで `close(out)` を使うことで、ファイルが開かれすぎないようにする
            if (out) close(out);
            out = dir_out_ "/" filename ".fa"

            # ヘッダー行を出力
            print > out
            next # 次の行へスキップ
        }

        # 各行を出力ファイルに書き込む
        { print > toupper(out) }

    ' dir_out_="$dir_out_" "$in_contig_"

(1-5)それぞれの配列ごとに調べる

    # megablast search of contig against itself
    out_blast_each_ = "#{dir_out_each_}/megablast.#{entry.definition}.txt"
    if [ $(grep -c #{entry.definition} #{out_blast_self_}) -gt 1 ]; then
        grep #{entry.definition} #{out_blast_self_} > #{out_blast_each_}
        # get contig length (BLAST position is 1-based)
        LENGTH=$(cat #{out_blast_each_} | head -n1 | cut -f 4)
        # extract putative circular contigs
        cat #{out_blast_each_} | tail -n +2 | grep -w ${LENGTH} | awk -F "\t" '{OFS="\t"} {if($4>=#{al_self} && $9==1) print}' >> ${OUT_}

        # get position of the overlap between 3' and 5' end
        POS_DUP=$(cat #{out_blast_each_} | sort -t$'\t' -k4 -n -r | tail -n +2 | grep -w ${LENGTH} | awk -F "\t" '{OFS="\t"} {if($4>=#{al_self} && $9==1) print $7}' | head -n 1)
        if [ -n "${POS_DUP}" ]; then
            POS_END=`expr ${POS_DUP} - 1`
        else
            POS_END=0"
        fi

        # get circlular contig
        if [ ${POS_END} -ge #{len_c} ]; then
            POS_END=`expr ${POS_DUP} - 1`
            # write circular contig in fasta format
            SEQ=$(sed -n 2p #{query_each_} | cut -c 1-${POS_END})
            echo ">#{entry.definition}" > #{dir_out_circular_}/#{entry.definition}.cut.fa
            echo "${SEQ}" >> #{dir_out_circular_}/#{entry.definition}.cut.fa
            # extend circular contig with whole contig sequence (duplicated sequences are concatenated.)
            SEQ_EX=$(sed -n 2p #{query_each_})
            echo ">#{entry.definition}" > #{dir_out_circular_}/#{entry.definition}.extended.fa
            echo "${SEQ}${SEQ_EX}" >> #{dir_out_circular_}/#{entry.definition}.extended.fa
        fi
        # removal of each files
        rm #{out_blast_each_}
    fi
    rm #{query_each_}

------



(2) blastdb
    # copy results to adjust to the existing scripts
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.fa  #{out}.fa
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.length.txt  #{out}.length.txt
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.extended.fa  #{out}.extended.fa
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.extended.length.txt  #{out}.extended.length.txt
    # blastdb
    ${MAKEBLASTDB_} -in #{out}.fa -out #{out} -dbtype nucl -parse_seqids

(3)
    # name information
    # updated (final) contigs
    cut -f 1 #{out}.length.txt > #{out}.txt
    cat #{out}.txt | perl -pe "s/l(\.\d+)$/n\1/" | perl -pe "s/c(\.\d+)$/n\1/" | paste - #{out}.txt > #{dir_out_}/name.updated.#{query_label}.#{len_l}.c_#{len_c}.txt
    # redundant (excluded) contigs
    cut -f 1,6 #{dir_out_}/contig.redundant.c_#{len_c}.length.txt | perl -pe "s/l(\.\d+)\t/n\1\t/" | perl -pe "s/c(\.\d+)\t/n\1\t/" > #{dir_out_}/name.redundant.#{query_label}.#{len_l}.c_#{len_c}.txt
    # all contigs
    cat #{dir_out_}/name.updated.#{query_label}.#{len_l}.c_#{len_c}.txt #{dir_out_}/name.redundant.#{query_label}.#{len_l}.c_#{len_c}.txt > #{dir_out_}/name.all.#{query_label}.#{len_l}.c_#{len_c}.txt

