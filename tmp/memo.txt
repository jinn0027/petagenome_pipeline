[05_circular_contigs.rb]

#SCRIPT_LENGTH_=get_sequence_length.py
SCRIPT_REDUNDANCY_=extract_contig_redundancy.3.rb
SCRIPT_FILTER_FA_=filter_fasta_by_id.py
#SCRIPT_RENAME_=filter_contig.rename.py


# parameter

# E-value cutoff for circular formation
e_thre = "1e-10"
# % identity for circular formation
pi_thre = "100"
# minimum alignment length for circular formation
al_thre = "50"

# % identity for removal of redundancy
pi_thre_rd = "95"
# % query coverage for removal of redundancy
qc_thre_rd = "95"

# minimum length for linear contigs
len_l = "5000"
# minimum length for circular contigs
len_c = "1500"

# % identity for circular formation
pi_self = 100
# alignment length for circular formation
al_self = 50

---

# input
query_fa_ = "#{dir_in_}/contig.#{query_label}.#{l_thre}.fa"

# output
out = "#{dir_out_}/contig.updated.#{query_label}.#{len_l}.c_#{len_c}"

##################

	# main script for exploring circular contigs
	f_qsub.puts "ruby ${SCRIPT_SELF_}  -d #{dir_out_}  -i #{query_fa_}  -n #{n_threads}  --len_l #{len_l} --len_c #{len_c} --pi_rd #{pi_thre_rd} --qc_rd #{qc_thre_rd} "

##################

h_params = ARGV.getopts('', 'dir_out_:', 'in_contig_:', 'n_threads:1', 'pi_self:100', 'al_self:50', 'pi_rd:98', 'qc_rd:98', 'len_l:5000', 'len_c:1500')

wdir_out_ = h_params["dir_out_"] # directory for outputs
in_contig_ = h_params["in_contig_"] # fasta file of contigs
n_threads = h_params["n_threads"] # number of threads used in blast search
# parameters for circular contig formation
pi_self = h_params["pi_self"] # % identity for circular formation
al_self = h_params["al_self"] # alignment length for circular formation
len_l = h_params["len_l"] # minimum length of linear contigs
len_c = h_params["len_c"] # minimum length of circular contigs
# parameters for redundant contig detection
pi_rd = h_params["pi_rd"] # % identity for removal of redundancy
qc_rd = h_params["qc_rd"] # % query coverage for removal of redundancy

###


pi_rd=pi_thre_rd
qc_rd=qc_thre_rd

###

# shori
(1) ruby ${SCRIPT_SELF_}  -d #{dir_out_} -i #{query_fa_}  -n #{n_threads} \
                          --len_l #{len_l} --len_c #{len_c} --pi_rd #{pi_thre_rd} --qc_rd #{qc_thre_rd}

------
[run_blastn_self_contig.3.rb]

# output files
out_blast_all_ = "#{dir_out_}/#{task}.all_vs_all.#{e_thre}.pi_#{pi_self}.txt"
out_blast_self_ = "#{dir_out_}/#{task}.self.#{e_thre}.pi_#{pi_self}.txt"
out_blast_circular_ = "#{dir_out_}/#{task}.circular.#{e_thre}.pi_#{pi_self}.al_#{al_self}.txt"
out_linear = "#{dir_out_}/contig.linear"
out_circular = "#{dir_out_}/contig.circular"
out_updated = "#{dir_out_}/contig.updated"

(1-1)データベースが作られていなかったらこれを作る
    # make blastdb if it does not exist.
    in_contig = "#{File.dirname(in_contig_)}/#{File.basename(in_contig_,'.*')}"
    if ! File.exist?("#{in_contig}.nsq") and ! File.exist?("#{in_contig}.nal")
        ${MAKEBLASTDB_} -in #{in_contig_}  -out #{in_contig}  -dbtype nucl  -parse_seqids
    end

(1-2)自分自身とblastn実行
    ${BLASTN_} -task #{task} -num_threads #{n_threads} -query #{in_contig_} \
               -db #{in_contig} -evalue #{e_thre} -perc_identity #{pi_self} -outfmt 6 -num_alignments 5 -out #{out_blast_all_}

(1-3)同じ配列がヒットしていたらそこだけを取る。
    awk -F "\t" '{OFS="\t"}  { if ($1 == $2) print $0 }' #{out_blast_all_} > #{out_blast_self_}

(1-4)配列一つ一つでFASTAファイルを分割
    awk '
        # ヘッダー行を検出
        /^>/ {
            # ヘッダー行から ">" とスペースを削除してファイル名を生成
            # gsub()でスペースをアンダースコアに置換し、より安全なファイル名にする
            filename = $0
            gsub(/^> *| */, "", filename)
            gsub(/ +/, "_", filename)

            # 新しいファイル名で出力ファイルを閉じて、開き直す
            # ここで `close(out)` を使うことで、ファイルが開かれすぎないようにする
            if (out) close(out);
            out = dir_out_ "/" filename ".fa"

            # ヘッダー行を出力
            print > out
            next # 次の行へスキップ
        }

        # 各行を出力ファイルに書き込む
        { print > toupper(out) }

    ' dir_out_="$dir_out_" "$in_contig_"

(1-5)それぞれの配列ごとに調べる

    # megablast search of contig against itself
    out_blast_each_ = "#{dir_out_each_}/megablast.#{entry.definition}.txt"
    if [ $(grep -c #{entry.definition} #{out_blast_self_}) -gt 1 ]; then
        grep #{entry.definition} #{out_blast_self_} > #{out_blast_each_}
        # get contig length (BLAST position is 1-based)
        LENGTH=$(cat #{out_blast_each_} | head -n1 | cut -f 4)
        # extract putative circular contigs
        cat #{out_blast_each_} | tail -n +2 | grep -w ${LENGTH} | awk -F "\t" '{OFS="\t"} {if($4>=#{al_self} && $9==1) print}' >> ${OUT_}

        # get position of the overlap between 3' and 5' end
        POS_DUP=$(cat #{out_blast_each_} | sort -t$'\t' -k4 -n -r | tail -n +2 | grep -w ${LENGTH} | awk -F "\t" '{OFS="\t"} {if($4>=#{al_self} && $9==1) print $7}' | head -n 1)
        if [ -n "${POS_DUP}" ]; then
            POS_END=`expr ${POS_DUP} - 1`
        else
            POS_END=0"
        fi

        # get circlular contig
        if [ ${POS_END} -ge #{len_c} ]; then
            POS_END=`expr ${POS_DUP} - 1`
            # write circular contig in fasta format
            SEQ=$(sed -n 2p #{query_each_} | cut -c 1-${POS_END})
            echo ">#{entry.definition}" > #{dir_out_circular_}/#{entry.definition}.cut.fa
            echo "${SEQ}" >> #{dir_out_circular_}/#{entry.definition}.cut.fa
            # extend circular contig with whole contig sequence (duplicated sequences are concatenated.)
            SEQ_EX=$(sed -n 2p #{query_each_})
            echo ">#{entry.definition}" > #{dir_out_circular_}/#{entry.definition}.extended.fa
            echo "${SEQ}${SEQ_EX}" >> #{dir_out_circular_}/#{entry.definition}.extended.fa
        fi
        # removal of each files
        rm #{out_blast_each_}
    fi
    rm #{query_each_}

(1-6)
# concatenate circular contigs
cat  #{dir_out_circular_}/*.cut.fa > #{out_circular}.c_#{len_c}.all.fa
cat  #{dir_out_circular_}/*.extended.fa > #{out_circular}.c_#{len_c}.all.extended.fa

(1-7)
# get linear contigs
python ${SCRIPT_LENGTH_} #{out_circular}.c_#{len_c}.all.fa > #{out_circular}.c_#{len_c}.all.length.txt
wait
python ${SCRIPT_FILTER_FA_} -f #{out_circular}.c_#{len_c}.all.length.txt #{in_contig_} > #{out_linear}.all.fa

(1-8)
#------------------------------
# rename contigs:  circular:c  linear:l
#------------------------------
wait
cat #{dir_out_circular_}/*.cut.fa | perl -pe "s/n(\.\d+)$/c\1/" > #{out_circular}.c_#{len_c}.all.fa
cat  #{dir_out_circular_}/*.extended.fa | perl -pe "s/n(\.\d+)$/c\1/" > #{out_circular}.c_#{len_c}.all.extended.fa
python ${SCRIPT_FILTER_FA_} -f #{out_circular}.c_#{len_c}.all.length.txt #{in_contig_} | perl -pe "s/n(\.\d+)$/l\1/" > #{out_linear}.all.fa

(1-9)
# get length of contigs
python ${SCRIPT_LENGTH_} #{out_circular}.c_#{len_c}.all.fa > #{out_circular}.c_#{len_c}.all.length.txt
python ${SCRIPT_LENGTH_} #{out_circular}.c_#{len_c}.all.extended.fa > #{out_circular}.c_#{len_c}.all.extended.length.txt
python ${SCRIPT_LENGTH_} #{out_linear}.all.fa > #{out_linear}.all.length.txt"

(1-10)
# updated contigs
cat  #{out_circular}.c_#{len_c}.all.fa  #{out_linear}.all.fa > #{out_updated}.c_#{len_c}.all.fa
python ${SCRIPT_LENGTH_} #{out_updated}.c_#{len_c}.all.fa > #{out_updated}.c_#{len_c}.all.length.txt

(1-11)
#------------------------------
# removal of redundancy in contigs
#------------------------------
out_blast_rd = "#{dir_out_}/#{task}.redundancy.updated.c_#{len_c}.#{e_thre}.pi_#{pi_rd}
out_rd_info_ = "#{dir_out_}/info.redundancy.updated.c_#{len_c}.#{e_thre}.pi_#{pi_rd}.qc_#{qc_rd}.txt
out_ex_contig_ = "#{dir_out_}/contig.redundant.c_#{len_c}.length.txt

# blast search for extracting redundancy
${MAKEBLASTDB_} -in #{out_updated}.c_#{len_c}.all.fa  -out #{out_updated}.c_#{len_c}.all  -dbtype nucl  -parse_seqids
${BLASTN_} -task #{task} -num_threads #{n_threads} -query #{out_updated}.c_#{len_c}.all.fa -db #{out_updated}.c_#{len_c}.all -evalue #{e_thre} -perc_identity #{pi_rd} -outfmt 6 -num_alignments 50 -out #{out_blast_rd}.all.txt
awk -F "\t" '{OFS="\t"}  { if ($1 != $2) print $0 }' #{out_blast_rd}.all.txt > #{out_blast_rd}.txt

(1-12)
# extract redundant contigs
ruby ${SCRIPT_REDUNDANCY_}  -b #{out_blast_rd}.txt  -l #{out_updated}.c_#{len_c}.all.length.txt  -c #{qc_rd}  -d 6  -i #{out_rd_info_}  -o #{out_ex_contig_}

(1-13)
# get deduplicated contigs
python ${SCRIPT_FILTER_FA_} -f #{out_ex_contig_} #{out_linear}.all.fa > #{out_linear}.fa
python ${SCRIPT_FILTER_FA_} -f #{out_ex_contig_} #{out_circular}.c_#{len_c}.all.fa > #{out_circular}.c_#{len_c}.fa
python ${SCRIPT_FILTER_FA_} -f #{out_ex_contig_} #{out_circular}.c_#{len_c}.all.extended.fa > #{out_circular}.c_#{len_c}.extended.fa
python ${SCRIPT_FILTER_FA_} -f #{out_ex_contig_} #{out_updated}.c_#{len_c}.all.fa > #{out_updated}.c_#{len_c}.fa

python ${SCRIPT_LENGTH_} #{out_linear}.fa > #{out_linear}.length.txt
python ${SCRIPT_LENGTH_} #{out_circular}.c_#{len_c}.fa > #{out_circular}.c_#{len_c}.length.txt
python ${SCRIPT_LENGTH_} #{out_circular}.c_#{len_c}.extended.fa > #{out_circular}.c_#{len_c}.extended.length.txt
python ${SCRIPT_LENGTH_} #{out_updated}.c_#{len_c}.fa > #{out_updated}.c_#{len_c}.length.txt

(1-14)
#------------------------------
# extract large contigs
#------------------------------
python ${SCRIPT_RENAME_} -min #{len_l} #{out_linear}.fa > #{out_linear}.#{len_l}.fa
python ${SCRIPT_LENGTH_} #{out_linear}.#{len_l}.fa > #{out_linear}.#{len_l}.length.txt

(1-15)
# updated contigs
cat  #{out_circular}.c_#{len_c}.fa  #{out_linear}.#{len_l}.fa > #{out_updated}.#{len_l}.c_#{len_c}.fa
cat  #{out_circular}.c_#{len_c}.extended.fa  #{out_linear}.#{len_l}.fa > #{out_updated}.#{len_l}.c_#{len_c}.extended.fa
cat  #{out_circular}.c_#{len_c}.length.txt  #{out_linear}.#{len_l}.length.txt | sort -k 1,1  > #{out_updated}.#{len_l}.c_#{len_c}.length.txt
cat  #{out_circular}.c_#{len_c}.extended.length.txt  #{out_linear}.#{len_l}.length.txt | sort -k 1,1  > #{out_updated}.#{len_l}.c_#{len_c}.extended.length.txt


------



(2) blastdb
    # copy results to adjust to the existing scripts
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.fa  #{out}.fa
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.length.txt  #{out}.length.txt
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.extended.fa  #{out}.extended.fa
    cp  #{dir_out_}/contig.updated.#{len_l}.c_#{len_c}.extended.length.txt  #{out}.extended.length.txt

(4)
	# blastdb
	f_qsub.puts "${MAKEBLASTDB_} -in #{out}.fa -out #{out} -dbtype nucl -parse_seqids"

(5)
    # name information
    # updated (final) contigs
    cut -f 1 #{out}.length.txt > #{out}.txt
    cat #{out}.txt | perl -pe "s/l(\.\d+)$/n\1/" | perl -pe "s/c(\.\d+)$/n\1/" | paste - #{out}.txt > #{dir_out_}/name.updated.#{query_label}.#{len_l}.c_#{len_c}.txt
    # redundant (excluded) contigs
    cut -f 1,6 #{dir_out_}/contig.redundant.c_#{len_c}.length.txt | perl -pe "s/l(\.\d+)\t/n\1\t/" | perl -pe "s/c(\.\d+)\t/n\1\t/" > #{dir_out_}/name.redundant.#{query_label}.#{len_l}.c_#{len_c}.txt
    # all contigs
    cat #{dir_out_}/name.updated.#{query_label}.#{len_l}.c_#{len_c}.txt #{dir_out_}/name.redundant.#{query_label}.#{len_l}.c_#{len_c}.txt > #{dir_out_}/name.all.#{query_label}.#{len_l}.c_#{len_c}.txt

